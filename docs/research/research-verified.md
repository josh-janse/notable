# Phase 0: Research - VERIFIED Implementation Patterns

**Feature**: 001-process-note-app
**Created**: 2025-11-20
**Verified**: 2025-11-20
**Status**: Complete - All patterns verified against official 2024 documentation

## Summary of Verification

All implementation patterns have been verified against official documentation. Key findings:

1. **Tiptap Open Source is FREE (MIT)** - No need for expensive Pro version
2. **Novel is also FREE** - Built on Tiptap, adds value with AI features
3. **AI SDK embeddings** - Verified correct usage through AI SDK gateway
4. **Deepgram SDK v3** - Simplified patterns confirmed
5. **pgvector HNSW** - Optimal configuration verified
6. **pg_cron Supabase** - Local development caveats identified

---

## 1. Markdown Editor: Tiptap vs Novel ‚úÖ VERIFIED

### Key Finding: Tiptap Open Source is FREE

**IMPORTANT CORRECTION**: Tiptap has a **free, MIT-licensed open-source version** that includes everything needed for custom nodes (locked headers). The expensive Platform ($299-999/mo) is only for managed collaboration/AI features.

### Comparison

| Feature | Tiptap OSS (FREE) | Novel (FREE) | Tiptap Platform (PAID) |
|---------|-------------------|--------------|------------------------|
| License | MIT | MIT | Commercial |
| Custom Nodes | ‚úÖ Yes | ‚úÖ Yes (via Tiptap) | ‚úÖ Yes |
| Locked Headers | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| AI Features | ‚ùå No | ‚úÖ Built-in | ‚úÖ Managed |
| Collaboration | ‚ùå No (use Hocuspocus) | ‚ùå No | ‚úÖ Managed |
| Slash Commands | üîß Manual | ‚úÖ Built-in | ‚úÖ Built-in |
| Bundle Size | Minimal | Small overhead | N/A |
| Setup Complexity | Moderate | Easy | Easy |
| Cost | **FREE** | **FREE** | $299-999/mo |

### Recommendation: **Novel** (FREE, built on Tiptap)

**Why Novel over raw Tiptap:**
- Same Tiptap foundation (you're not losing anything)
- AI-powered autocompletions included
- Slash commands pre-configured
- Notion-style UX out of the box
- Built with Vercel AI SDK (matches your stack)
- Faster setup, less boilerplate

**Source**: https://tiptap.dev/open-source-to-platform

### Implementation with Novel

```bash
npm install novel
```

```typescript
// components/notes/note-editor.tsx
'use client'

import { Editor } from 'novel'
import { useState } from 'react'

export function NoteEditor({ noteId, template }: { noteId: string; template: NoteTemplate }) {
  const [content, setContent] = useState('')

  return (
    <Editor
      defaultValue={content}
      onUpdate={(editor) => {
        const json = editor.getJSON()
        setContent(JSON.stringify(json))
      }}
      // Add custom extensions for locked headers
      extensions={[
        // Your custom locked header extension
      ]}
      className="min-h-[500px]"
    />
  )
}
```

**Custom Locked Header Extension** (works with both Tiptap and Novel):

```typescript
// lib/editor/locked-header-extension.ts
import { Node } from '@tiptap/core'

export const LockedHeader = Node.create({
  name: 'lockedHeader',
  group: 'block',
  content: 'text*',

  addAttributes() {
    return {
      level: { default: 2 },
      locked: { default: true },
      text: { default: '' },
    }
  },

  parseHTML() {
    return [{ tag: 'h[1-6][data-locked="true"]' }]
  },

  renderHTML({ node }) {
    return [
      `h${node.attrs.level}`,
      {
        'data-locked': 'true',
        class: 'locked-header bg-gray-100 cursor-not-allowed',
      },
      node.attrs.text,
    ]
  },

  addKeyboardShortcuts() {
    return {
      // Prevent editing locked headers
      Backspace: () => {
        const { $from } = this.editor.state.selection
        return $from.parent.type.name === 'lockedHeader'
      },
      Delete: () => {
        const { $from } = this.editor.state.selection
        return $from.parent.type.name === 'lockedHeader'
      },
    }
  },
})
```

---

## 2. Real-Time Transcription: Deepgram SDK v3 ‚úÖ VERIFIED

### Verified Implementation (Deepgram SDK v3)

**Package**: `@deepgram/sdk` (v3.x)
**Documentation**: https://github.com/deepgram/deepgram-js-sdk

```typescript
// lib/deepgram/client.ts
import { createClient } from '@deepgram/sdk'

export function initializeDeepgram(apiKey: string) {
  return createClient(apiKey)
}

// hooks/use-transcription.ts
'use client'

import { useState, useRef, useCallback } from 'react'
import { initializeDeepgram } from '@/lib/deepgram/client'

export function useTranscription() {
  const [transcript, setTranscript] = useState('')
  const [isRecording, setIsRecording] = useState(false)
  const connectionRef = useRef<any>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)

  const startTranscription = useCallback(async () => {
    const apiKey = process.env.NEXT_PUBLIC_DEEPGRAM_API_KEY!
    const deepgram = initializeDeepgram(apiKey)

    // Create live transcription connection
    const connection = deepgram.listen.live({
      model: 'nova-2',
      language: 'en-US',
      smart_format: true,
      punctuate: true,
      interim_results: true,
    })

    connectionRef.current = connection

    // Event handlers
    connection.on('open', () => {
      console.log('Deepgram connection opened')
      setIsRecording(true)
    })

    connection.on('transcript', (data: any) => {
      const words = data.channel.alternatives[0].words
      const transcript = data.channel.alternatives[0].transcript

      if (transcript && transcript.length > 0) {
        setTranscript((prev) => prev + ' ' + transcript)
      }
    })

    connection.on('error', (error: any) => {
      console.error('Deepgram error:', error)
    })

    connection.on('close', () => {
      console.log('Deepgram connection closed')
      setIsRecording(false)
    })

    // Get microphone audio
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
      }
    })

    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: 'audio/webm',
    })

    mediaRecorderRef.current = mediaRecorder

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0 && connection.getReadyState() === 1) {
        connection.send(event.data)
      }
    }

    mediaRecorder.start(250) // Send audio chunks every 250ms
  }, [])

  const stopTranscription = useCallback(() => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop())
    }

    if (connectionRef.current) {
      connectionRef.current.finish()
    }

    setIsRecording(false)
  }, [])

  return {
    transcript,
    isRecording,
    startTranscription,
    stopTranscription,
    clearTranscript: () => setTranscript(''),
  }
}
```

### Key Changes from Research Document
- ‚úÖ Import from `@deepgram/sdk` (not `@deepgram/client`)
- ‚úÖ Use `createClient()` function
- ‚úÖ Events: `on('open')`, `on('transcript')`, `on('error')`, `on('close')`
- ‚úÖ `connection.send()` for audio data
- ‚úÖ `connection.finish()` to close gracefully

---

## 3. LLM Field Extraction: AI SDK streamObject ‚úÖ VERIFIED

### Verified Implementation (AI SDK v5)

**Documentation**: https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data

```typescript
// app/api/notes/[noteId]/extract/route.ts
import { streamObject } from 'ai'
import { openai } from '@ai-sdk/openai'
import { z } from 'zod'
import { createClient } from '@/lib/supabase/server'

const extractionSchema = z.object({
  subjective: z.string().describe('Client reported feelings and concerns'),
  objective: z.string().describe('Observed behaviors, mood, appearance'),
  assessment: z.string().describe('Clinical impression and progress'),
  plan: z.string().describe('Treatment plan and next steps'),
  missingFields: z.array(z.string()).optional().describe('Required fields not found'),
  clarifyingQuestions: z.array(z.string()).optional().describe('Questions for practitioner'),
})

export async function POST(
  request: Request,
  { params }: { params: { noteId: string } }
) {
  const { transcription, templateId } = await request.json()

  const supabase = await createClient()
  const template = await getTemplate(templateId)

  const result = streamObject({
    model: openai('gpt-4-turbo'),
    schema: extractionSchema,
    system: `You are a clinical notes assistant. Extract information from the session transcription and map it to the template fields. If critical information is missing, identify what needs clarification.`,
    prompt: `Template structure: ${JSON.stringify(template.structure)}\n\nTranscription: ${transcription}`,
    onFinish: async ({ object }) => {
      // Save extracted fields to database
      await supabase
        .from('notes')
        .update({
          extracted_fields: object,
          status: object.missingFields?.length ? 'draft' : 'completed'
        })
        .eq('id', params.noteId)
    },
  })

  // Return streaming response
  return result.toTextStreamResponse()
}
```

### Client-Side Hook ‚úÖ VERIFIED

```typescript
// hooks/use-note-extraction.ts
'use client'

import { experimental_useObject as useObject } from 'ai/react'
import { z } from 'zod'

const extractionSchema = z.object({
  subjective: z.string(),
  objective: z.string(),
  assessment: z.string(),
  plan: z.string(),
  missingFields: z.array(z.string()).optional(),
  clarifyingQuestions: z.array(z.string()).optional(),
})

export function useNoteExtraction(noteId: string) {
  const { object, submit, isLoading, error } = useObject({
    api: `/api/notes/${noteId}/extract`,
    schema: extractionSchema,
  })

  return {
    extractedFields: object,
    extract: submit,
    isExtracting: isLoading,
    error,
  }
}
```

### Key Corrections
- ‚úÖ `streamObject` is correct for structured data
- ‚úÖ `toTextStreamResponse()` returns proper stream
- ‚úÖ `useObject` is `experimental_useObject` in AI SDK
- ‚úÖ AI Gateway: Configure via model identifier format (e.g., `'openai/gpt-4-turbo'`)

---

## 4. Semantic Search: AI SDK Embeddings ‚úÖ VERIFIED

### Verified Implementation (AI SDK Embeddings)

**IMPORTANT**: Use AI SDK as gateway for embeddings (not direct OpenAI)
**Documentation**: https://ai-sdk.dev/docs/ai-sdk-core/embeddings

```typescript
// lib/ai/embeddings.ts
import { embed, embedMany } from 'ai'
import { openai } from '@ai-sdk/openai'

export async function generateEmbedding(text: string): Promise<number[]> {
  const { embedding } = await embed({
    model: openai.textEmbeddingModel('text-embedding-3-small'),
    value: text,
  })

  return embedding
}

export async function generateBatchEmbeddings(texts: string[]): Promise<number[][]> {
  const { embeddings } = await embedMany({
    model: openai.textEmbeddingModel('text-embedding-3-small'),
    values: texts,
    maxParallelCalls: 3, // Batch processing
  })

  return embeddings
}

// app/api/notes/[noteId]/route.ts (PATCH handler)
import { generateEmbedding } from '@/lib/ai/embeddings'
import { createClient } from '@/lib/supabase/server'

export async function PATCH(
  request: Request,
  { params }: { params: { noteId: string } }
) {
  const { markdown_content } = await request.json()
  const supabase = await createClient()

  // Generate embedding
  const embedding = await generateEmbedding(markdown_content)

  // Update note and embedding
  await supabase.from('notes').update({ markdown_content }).eq('id', params.noteId)
  await supabase
    .from('note_embeddings')
    .upsert({ note_id: params.noteId, embedding })

  return Response.json({ success: true })
}

// app/api/search/route.ts
import { generateEmbedding } from '@/lib/ai/embeddings'
import { createClient } from '@/lib/supabase/server'

export async function POST(request: Request) {
  const { query, client_id, match_threshold = 0.7, limit = 10 } = await request.json()
  const supabase = await createClient()

  // Generate query embedding
  const queryEmbedding = await generateEmbedding(query)

  // Vector search
  const { data, error } = await supabase.rpc('search_notes', {
    query_embedding: queryEmbedding,
    filter_client_id: client_id || null,
    match_threshold,
    match_count: limit,
  })

  if (error) throw error

  return Response.json({ results: data, query })
}
```

### Key Corrections
- ‚úÖ Use `embed` from `'ai'` (not direct OpenAI SDK)
- ‚úÖ Use `openai.textEmbeddingModel()` method
- ‚úÖ `embedMany` for batch processing with `maxParallelCalls`
- ‚úÖ Returns plain `number[]` array (compatible with pgvector)
- ‚úÖ Built-in retry logic and error handling

---

## 5. pgvector Search: HNSW Index ‚úÖ VERIFIED

### Verified Optimal Configuration

**Documentation**: https://github.com/pgvector/pgvector
**Best Practices**: Google Cloud Blog, AWS Blog, Neon Blog

```sql
-- Create vector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create embeddings table with optimal dimension
CREATE TABLE note_embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  note_id UUID NOT NULL REFERENCES notes(id) ON DELETE CASCADE UNIQUE,
  embedding vector(1536), -- text-embedding-3-small dimension
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create HNSW index for cosine similarity (OPTIMAL for 1536 dims)
CREATE INDEX idx_note_embeddings_hnsw_cosine
ON note_embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- For better recall (slower build, better search):
-- WITH (m = 24, ef_construction = 128);

-- RLS Policies
ALTER TABLE note_embeddings ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users view own embeddings"
  ON note_embeddings FOR SELECT
  USING (
    EXISTS (
      SELECT 1 FROM notes
      WHERE notes.id = note_embeddings.note_id
        AND notes.practitioner_id = auth.uid()
    )
  );

-- Search function with RLS
CREATE OR REPLACE FUNCTION search_notes(
  query_embedding vector(1536),
  filter_client_id UUID DEFAULT NULL,
  match_threshold float DEFAULT 0.7,
  match_count int DEFAULT 10
)
RETURNS TABLE (
  note_id UUID,
  client_id UUID,
  client_name TEXT,
  content TEXT,
  session_date TIMESTAMPTZ,
  similarity float
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  RETURN QUERY
  SELECT
    n.id AS note_id,
    n.client_id,
    c.full_name AS client_name,
    n.markdown_content AS content,
    n.session_date,
    1 - (ne.embedding <=> query_embedding) AS similarity
  FROM notes n
  JOIN note_embeddings ne ON ne.note_id = n.id
  JOIN clients c ON c.id = n.client_id
  WHERE 1 - (ne.embedding <=> query_embedding) > match_threshold
    AND n.practitioner_id = auth.uid()
    AND (filter_client_id IS NULL OR n.client_id = filter_client_id)
  ORDER BY ne.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

### Key Verified Points
- ‚úÖ **HNSW is optimal** for high-dimensional vectors (1536 dims)
- ‚úÖ Use `vector_cosine_ops` for cosine similarity (not `vector_l2_ops`)
- ‚úÖ `<=>` operator for cosine distance (correct)
- ‚úÖ `1 - distance` converts distance to similarity [0-1]
- ‚úÖ Default `m=16, ef_construction=64` is good starting point
- ‚úÖ Increase `m` and `ef_construction` for better recall at cost of build time
- ‚úÖ NULL vectors are NOT indexed (important for partial data)

### Performance Tuning

```sql
-- Adjust search parameters at runtime
SET hnsw.ef_search = 100; -- Default is 40, higher = better recall, slower search

-- For better recall during search without rebuilding index:
SELECT set_config('hnsw.ef_search', '200', false);
```

---

## 6. Session Notifications: pg_cron ‚úÖ VERIFIED

### Verified Implementation

**Documentation**: https://supabase.com/docs/guides/database/extensions/pg_cron
**Caveat**: Local development requires workarounds

```sql
-- Enable extension
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Schedule daily notification job at 6 AM
SELECT cron.schedule(
  'generate-session-notifications',
  '0 6 * * *', -- Cron expression: minute hour day month weekday
  $$
  INSERT INTO notifications (practitioner_id, client_id, note_id, type, title, content, created_at)
  SELECT
    n.practitioner_id,
    n.client_id,
    n.id AS note_id,
    'session_reminder' AS type,
    'Upcoming Session: ' || c.full_name AS title,
    jsonb_build_object(
      'scheduled_date', n.next_session_date,
      'previous_session_summary', LEFT(n.markdown_content, 200),
      'follow_ups', n.follow_up_items,
      'session_count', (
        SELECT COUNT(*)
        FROM notes
        WHERE client_id = n.client_id AND status = 'approved'
      )
    ) AS content,
    NOW() AS created_at
  FROM notes n
  JOIN clients c ON c.id = n.client_id
  WHERE n.next_session_date = CURRENT_DATE
    AND n.follow_up_items IS NOT NULL
    AND n.status = 'approved'
    AND NOT EXISTS (
      SELECT 1 FROM notifications notif
      WHERE notif.client_id = n.client_id
        AND notif.type = 'session_reminder'
        AND notif.created_at::date = CURRENT_DATE
    );
  $$
);

-- View scheduled jobs
SELECT * FROM cron.job;

-- Unschedule a job
SELECT cron.unschedule('generate-session-notifications');
```

### Local Development Workaround ‚ö†Ô∏è

**Issue**: pg_cron in local Supabase requires `cron.database_name` configuration

```bash
# Option 1: Add to postgresql.conf in Docker
# supabase/config/postgresql.conf
shared_preload_libraries = 'pg_cron'
cron.database_name = 'postgres'

# Option 2: Test manually during development
# Run the cron job SQL manually to test:
# Execute the INSERT statement directly
```

### Monitoring & Debugging

```sql
-- Check job run history
SELECT * FROM cron.job_run_details
ORDER BY start_time DESC
LIMIT 10;

-- Enable logging
SELECT cron.schedule(
  'job-name',
  '0 6 * * *',
  $$
  INSERT INTO cron_logs (job_name, run_at, status)
  VALUES ('generate-session-notifications', NOW(), 'started');

  -- Your job SQL here

  INSERT INTO cron_logs (job_name, run_at, status)
  VALUES ('generate-session-notifications', NOW(), 'completed');
  $$
);
```

### Timezone Handling ‚úÖ

```sql
-- Set timezone for cron execution
SELECT cron.schedule(
  'generate-session-notifications',
  '0 6 * * *',
  $$SET timezone = 'America/New_York'; /* Your actual job SQL */$$
);

-- Or use UTC and convert in application
-- Supabase production uses UTC by default
```

---

## Updated Architectural Decisions Summary

| Decision Area | Selected Approach | Verification Status | Documentation |
|---------------|-------------------|---------------------|---------------|
| **Markdown Editor** | **Novel (FREE)** over Tiptap Pro | ‚úÖ Verified - Both MIT licensed | [Novel](https://novel.sh), [Tiptap OSS](https://tiptap.dev/open-source-to-platform) |
| **Transcription** | Deepgram SDK v3 (client-side) | ‚úÖ Verified - Correct imports & events | [Deepgram SDK](https://github.com/deepgram/deepgram-js-sdk) |
| **LLM Extraction** | AI SDK `streamObject` + Zod | ‚úÖ Verified - Correct API | [AI SDK Structured Data](https://ai-sdk.dev/docs/ai-sdk-core/generating-structured-data) |
| **Embeddings** | AI SDK `embed` gateway | ‚úÖ Verified - NOT direct OpenAI | [AI SDK Embeddings](https://ai-sdk.dev/docs/ai-sdk-core/embeddings) |
| **Vector Search** | pgvector HNSW + cosine | ‚úÖ Verified - Optimal config | [pgvector](https://github.com/pgvector/pgvector) |
| **Notifications** | pg_cron (with local workaround) | ‚úÖ Verified - Supabase caveats | [Supabase pg_cron](https://supabase.com/docs/guides/database/extensions/pg_cron) |

### Major Corrections from Initial Research

1. **Tiptap is FREE** - No need for expensive Pro ($299-999/mo) for basic features
2. **Novel is the better choice** - FREE, built on Tiptap, includes AI features
3. **AI SDK embeddings** - Must use `embed` from `'ai'`, not direct OpenAI
4. **Deepgram SDK v3** - Import from `@deepgram/sdk`, use `createClient()`
5. **pgvector HNSW** - Confirmed optimal for 1536-dim vectors
6. **pg_cron local dev** - Requires postgresql.conf changes in Docker

All implementation code has been updated to match verified patterns from 2024 documentation.
